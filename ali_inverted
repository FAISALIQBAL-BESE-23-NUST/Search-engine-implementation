import pandas as pd
import os
import sys

# Function to load the forward index chunks
def load_forward_index_chunks(forward_index_folder):
    """
    Load forward index chunks into a list of dictionaries.
    Each dictionary contains 'doc_id' and a list of 'word_ids'.
    """
    forward_index = []
    
    # Iterate through all forward index chunk files
    for chunk_file in os.listdir(forward_index_folder):
        if chunk_file.endswith(".csv"):
            chunk_path = os.path.join(forward_index_folder, chunk_file)
            chunk_df = pd.read_csv(chunk_path)
            
            # Add each document's information (doc_id and word_ids) to the forward index
            for _, row in chunk_df.iterrows():
                doc_id = row['doc_id']
                word_ids = eval(row['word_ids'])  # Convert string representation of list to actual list
                forward_index.append({'doc_id': doc_id, 'word_ids': word_ids})
    
    return forward_index


# Function to create an inverted index from the forward index
def create_inverted_index_from_forward(forward_index, output_folder, max_chunk_size_kb=3000):
    """
    Create an inverted index by mapping word IDs to document IDs.
    
    Args:
        forward_index (list): List of dictionaries containing doc_id and word_ids.
        output_folder (str): Folder where the inverted index chunks will be saved.
        max_chunk_size_kb (int): Maximum chunk file size in kilobytes (default is 3000KB).
    """
    inverted_index = {}
    chunk_counter = 1  # Initialize chunk counter
    current_chunk_size = 0  # Track current chunk size in bytes
    
    # Process each document in the forward index
    for entry in forward_index:
        doc_id = entry['doc_id']
        word_ids = entry['word_ids']
        
        # For each word ID, add the document ID to the inverted index
        for word_id in word_ids:
            if word_id not in inverted_index:
                inverted_index[word_id] = set()  # Use a set to avoid duplicates
            inverted_index[word_id].add(doc_id)  # Add the document ID to the set (no duplicates)
                
        # If the current chunk size exceeds max_chunk_size_kb, save and reset
        if current_chunk_size >= max_chunk_size_kb * 1024:  # Convert KB to Bytes
            # Save the current chunk to a CSV file
            chunk_filename = f"inverted_index_chunk_{chunk_counter}.csv"
            chunk_path = os.path.join(output_folder, chunk_filename)
            
            inverted_index_data = []
            for word_id, doc_ids in inverted_index.items():
                inverted_index_data.append({'word_id': word_id, 'doc_ids': list(doc_ids)})
            
            inverted_index_df = pd.DataFrame(inverted_index_data)
            inverted_index_df.to_csv(chunk_path, index=False)
            print(f"Inverted index chunk saved to {chunk_path}")
            
            # Reset the inverted index for the next chunk
            inverted_index = {}
            current_chunk_size = 0  # Reset current chunk size
            chunk_counter += 1
    
    # If any remaining data is left after processing all documents, save it as a final chunk
    if inverted_index:
        chunk_filename = f"inverted_index_chunk_{chunk_counter}.csv"
        chunk_path = os.path.join(output_folder, chunk_filename)
        
        inverted_index_data = []
        for word_id, doc_ids in inverted_index.items():
            inverted_index_data.append({'word_id': word_id, 'doc_ids': list(doc_ids)})
        
        inverted_index_df = pd.DataFrame(inverted_index_data)
        inverted_index_df.to_csv(chunk_path, index=False)
        print(f"Final inverted index chunk saved to {chunk_path}")


# Example usage
if __name__ == "__main__":
    # Define paths for forward index and output for inverted index chunks
    forward_index_folder = "forward_chunks"  # Folder containing forward index chunk CSVs
    output_folder = "inverted_index_chunks"  # Folder where the inverted index chunks will be saved

    # Create the output folder if it doesn't exist
    os.makedirs(output_folder, exist_ok=True)

    # Load the forward index chunks into memory
    forward_index = load_forward_index_chunks(forward_index_folder)
    
    # Create the inverted index from the forward index and save to chunks
    create_inverted_index_from_forward(forward_index, output_folder, max_chunk_size_kb=3000)
