import os
import pandas as pd
import string

def clean_word(word):
    """
    Clean the word by removing punctuation and converting to lowercase.

    Args:
        word (str): The word to be cleaned.

    Returns:
        str: The cleaned word.
    """
    # Remove punctuation and convert to lowercase
    cleaned_word = word.translate(str.maketrans("", "", string.punctuation)).lower()
    return cleaned_word

def create_lexicon_with_weights(chunk_folder, output_file, weights):
    """
    Create a lexicon by assigning unique word IDs and weights based on the source column.
    The lexicon will only read from the specified columns and clean the words by removing punctuation.

    Args:
        chunk_folder (str): Folder containing cleaned dataset chunks.
        output_file (str): Path to save the resulting lexicon CSV file.
        weights (dict): Weights assigned to words based on their column of origin.
    """
    word_dict = {}  # Dictionary to store words and their weights

    # Process each chunk
    for chunk_file in os.listdir(chunk_folder):
        if not chunk_file.endswith(".csv"):
            continue

        print(f"Processing chunk: {chunk_file}")
        chunk_path = os.path.join(chunk_folder, chunk_file)

        # Load the chunk
        df = pd.read_csv(chunk_path)

        # Process only the specified columns
        for column, weight in weights.items():
            if column in df.columns:  # Ensure the column exists
                df[column] = df[column].fillna("")  # Replace NaN with empty strings
                words = df[column].str.split()  # Split strings into words
                for word_list in words:
                    for word in word_list:
                        cleaned_word = clean_word(word)  # Clean the word
                        if cleaned_word:  # Ignore empty strings after cleaning
                            if cleaned_word in word_dict:
                                word_dict[cleaned_word] = max(word_dict[cleaned_word], weight)  # Keep the highest weight
                            else:
                                word_dict[cleaned_word] = weight

    # Assign unique IDs to words
    word_list = sorted(word_dict.keys())  # Sort words alphabetically
    lexicon = [{'word': word, 'word_id': idx, 'weight': word_dict[word]} for idx, word in enumerate(word_list, start=1)]

    # Save the lexicon to a CSV file
    lexicon_df = pd.DataFrame(lexicon)
    lexicon_df.to_csv(output_file, index=False)
    print(f"Lexicon with weights saved to: {output_file}")

# Example Usage
if __name__ == "__main__":
    chunk_folder = "cleaned_chunks"  # Folder containing cleaned dataset chunks
    output_file = "lexicon_with_weights_cleaned.csv"  # Path to save the lexicon

    # Define weights for columns
    weights = {
        'clean_text': 1,      # Lowest weight
        'clean_authors': 2,   # Higher weight
        'clean_tags': 3,      # Higher weight than authors
        'clean_title': 4      # Highest weight
    }

    create_lexicon_with_weights(chunk_folder, output_file, weights)
